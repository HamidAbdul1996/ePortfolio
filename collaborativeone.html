<!DOCTYPE HTML>
<!--
-->
<html>
	<head>
		<title>Generic - Forty by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo"><strong>hamidabdul</strong> <span></span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="landing.html">Landing</a></li>
							<li><a href="generic.html">Generic</a></li>
							<li><a href="elements.html">Elements</a></li>
						</ul>
						<ul class="actions stacked">
							<li><a href="#" class="button primary fit">Get Started</a></li>
							<li><a href="#" class="button fit">Log In</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main" class="alt">

						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h1>Collabrative Discussion: The 4th Industrial Revolution</h1>
									</header>
									<span class="image main"><img src="images/pic11.jp" alt="" /></span>
									<h3> Read the Schwab (2016) article from World Economic Forum and discuss the impact of industry 4.0 on the sector in which you are involved or interested.</h3>
									<h4><u>Initial Post</u></h4>
									<p>In alignment with Schwab's (2016) insights on Industry 4.0, the 2022 ransomware attack on the NHS Foundation Trust demonstrates the precarious balance between innovation and vulnerability in UK healthcare's digital transformation. The attack, which crippled Advanced's infrastructure, a key software provider to the NHS, precipitated a widespread reverting to manual processes, severely hindering patient services (Guardian, 2022). The reliance on pen-and-paper methods during the outage contrasts with the data-driven imperatives of Industry 4.0, which champions seamless integration and analysis of big data for enhanced decision-making and efficiency.
                                        The economic and reputational toll, compounded by the risks to patient care, highlights the sector's dependency on robust cybersecurity strategies—an essential facet of Industry 4.0's framework (Bligh-Wall, 2017). Furthermore, the incident highlighted the hidden risks of 'shadow IT systems', unofficial and unsanctioned tech solutions that can evade the rigorous security scrutiny required in a highly interconnected, data-centric healthcare ecosystem.
                                        The NHS ransomware attack underscores the need for stringent cybersecurity measures and exemplifies the potential of machine learning (ML) in enhancing data system security. ML algorithms could advance anomaly detection, recognising ransomware signatures before they inflict damage (Alraizza & Algarni, 2023). Predictive analytics powered by ML can forecast system vulnerabilities, bolstering pre-emptive defences (Kia et al, 2023). This case study encapsulates the application of sophisticated ML algorithms, aligning with Industry 4.0's emphasis on systemic development and data utilization.
                                        </p>
                                        <h4><u>Peer Response 1</u></h4>
                                        <p>Thank you for your insightful post, Rhys. It’s very interesting to consider how machine learning systems can perpetuate and even exacerbate societal biases.
                                            In the UK public sector, where I’m based, we’ve seen significant repercussions, one notable example being bias in AI tools used for benefits administration. There has been concern around the use of semi-automated systems that employ algorithms to flag potential benefits fraud, which are then reviewed by humans for final decisions on suspending claims. One member of parliament pointed out that in her constituency, a significant number of Bulgarian nationals had their benefits suspended and often on review, no evidence of fraud would be found. The Department of Work and Pensions has been using AI to detect benefits fraud since 2021 and maintains the algorithm doesn’t consider nationality, however, given the self-learning nature of these systems and the black box you mention, it’s difficult to determine precisely how they process and weigh the data they receive and how these might be perpetuating bias (The Guardian, 2023).
                                            Within clinical AI/ML, several strategies have been proposed to address issues of bias. Gebru et al (2018) highlighted the utility of 'datasheets for datasets', which can document an algorithm's performance limitations for specific population subgroups. While somewhat technical, these datasheets provide a comprehensive overview of the dataset's characteristics and inherent limitations, offering valuable insights into potential biases. Another advocated approach involves the expansive collection of data, with a particular focus on systemic factors influencing health access and outcomes. This broader data scope is crucial for understanding and addressing the root causes of disparities in healthcare (Kostick-Quenet et al, 2022).
                                            Additionally, the concept of a 'negative legacy' in datasets is brought to the forefront. This term refers to the problematic patterns embedded in historical data that continue to propagate bias. By conducting thorough evaluations of racial bias in algorithms, researchers can pinpoint the actual areas needing bias mitigation. This process not only illuminates the biases present in the data but also guides the development of more equitable AI/ML applications in clinical settings (Kostick-Quenet et al, 2022).
                                            </p>
                                            <h4><u>Peer Response 2</u></h4>
                                            <p> Thanks for your insightful post, Benson.
                                                You raise an interesting point in the shifts in the finance skills landscape with banks needing to either upskill existing staff or hire new talent proficient in AI. This trend isn’t confined to the financial sector alone. To give another example, the healthcare sector also faces a pressing need for AI upskilling. While the integration of AI has the potential to improve patient outcomes and reduce the workload of professionals, there is a need for significant training and upskilling of healthcare providers on the ethical and privacy concerns related to the use of AI in healthcare, which must be accompanied by rigorous headlines. You pointed out that companies like Samsung and Amazon have prohibited the use of generative AI. In healthcare, there are studies suggesting the use of these models to craft discharge summaries to enhance efficiency (Rao, 2023). However, as you rightly highlighted, there's a significant concern regarding how these models might retain data, which raises substantial privacy issues.
                                                In the public sector, where I work, the UK government has made notable investments to position itself as a global leader in AI. This includes a £950 million investment in areas like R&D and education as part of an extensive AI sector deal (Business Reporter, 2023). Nonetheless, a 2021 report from the Department for Digital, Media, Culture and Sport (DCMS) indicates that investing in data talent is one of the most significant challenges facing UK businesses and the third sector (DCMS, 2021). Deloitte (2019) underscores that as AI becomes more sophisticated, there's a gap in necessary AI and data management skills among public sector employees. Moreover, there's a perceived lack of encouragement for innovation and risk-taking within the sector.
                                                </p>
                                                <h4><u>Summary Post</u></h4>
                                                <p>The valuable insights from my peers have allowed me to reflect and add to my initial post.
                                                    My initial post brought to light the 2022 ransomware attack on the NHS Foundation Trust, illustrating the fine line between innovation and vulnerability in the UK’s push for digital healthcare. The incident made it clear that robust cybersecurity and the potential of machine learning to detect anomalies are more crucial than ever.
                                                    The responses from my peers delved deeper into the role of ML in cybersecurity. One highlighted the growing number of malware threats and how ML is constantly adapting to meet these challenges head-on (McAfee, 2016). Another introduced the UK government’s proactive strategies, such as the Defence Science and Technology Laboratory’s (DSTL) competition to encourage innovative solutions in defence and security (The Defence Science and Technology Laboratory, 2023).
                                                    Other posts by peers have highlighted the importance of upskilling workforces in AI and concerns around machine learning bias. As AI and ML increasingly influence various sectors, addressing inherent biases and ensuring ethical, fair, and transparent practices is paramount. Additionally, the rapid evolution of industries under the influence of these technologies underscores the necessity for the workforce to adapt, enhancing their skills to leverage AI.
                                                    In my initial post on the impact of Industry 4.0, I touched on cybersecurity. Yet, I am particularly interested in augmented reality (AR), a field gaining momentum, especially after Apple's Vision Pro debut. Industry 4.0 has supercharged AR, making it not just more immersive but widely usable. For example, the Internet of Things (IoT) has made it possible to blend real-time data into AR experiences, vastly improving what users can see and do. Meanwhile, machine learning has been sharpening AR's ability to recognise objects, map spaces, and tailor experiences to individual users. However, merging these technologies also brings new challenges for machine learning professionals. 
                                                    One area where AR causes challenges is in dealing with privacy and intellectual property. When AR mixes real-world scenes with digital elements, the lines around copyright and ownership blur, potentially sparking complex legal battles. Moreover, using AR in public places brings up ethical questions about consent; people might find themselves part of an AR scenario without choosing to be (Harborth & Pappe, 2021). Machine learning professionals must ensure people stay in control of how they're involved and how their data is used. Finally, like other AI fields, AR can also carry forward any biases in its training data or algorithms, making fairness and anti-discrimination efforts essential. A study by Howard and Borenstein (2018) discusses how bias and social inequity can manifest in AR This is demonstrated As we step further into Industry 4.0, staying alert to these evolving and sometimes sector-specific challenges is vital for machine learning professionals. 
                                                    </p>
                                                    <h4><u>Reflection</u></h4>
                                                    <p> While each field presents its own set of challenges, there are several recurring issues made clear in our collaborative discussions that all machine learning professionals ought to be aware of and address. These are bias, data ownership, and accountability. One of the most pressing concerns is around how machine learning systems can perpetuate and exacerbate societal biases. I work in the public sector, and there was a concerning instance recently where an AI tool intended for benefits administration displayed potential bias. The tool was used to identify suspected benefits fraud and flagged a significant number of Bulgarian nationals consequently leading to the suspension of their benefits. Often on review, no evidence of fraud would be found (The Guardian, 2023). Now the Department of Works and Pensions maintains that the AI does not consider nationality but given the self-learning nature of these algorithms and the black box, it is difficult to determine precisely how they process and weigh the data they receive and how these might be perpetuating bias, and this is a point all machine learning professionals should be aware of and compelled to address.</p>
                                                    <h4><u>Reference List</u></h4>
													<p>
														<li>Alraizza, A. & Algarni, A. (2023) Ransomware Detection Using Machine Learning: A Survey.  Big Data Cognitive Computing. 7(3): 143. DOI: https://doi.org/10.3390/bdcc7030143</li>
														<li> Bligh-Wall (2017) Industry 4.0: Security imperatives for IoT – convergin networks, increasing risks. Cyber Security: A Peer – Reviewed Journal. 1(1): 61-68</li>
														<li>The Guardian (2022) NHS ransomware attack: what happened and how bad is it? Available from: https://www.theguardian.com/technology/2022/aug/11/nhs-ransomware-attack-what-happened-and-how-bad-is-it. [Accessed 8th November 2023]. </li>
														<li> Kia, A.N., Murphy, F., Sheehan, B. & Shannon, D. (2023) A cyber risk prediction model using common vulnerabilities and exposures. Expert Systems with Applications. 237</li>
														<li> Open Access Government (2022) 50% of UK organisations at risk of shadow IT security threats. Available from: https://www.openaccessgovernment.org/organisations-risk-shadow-it-security-threat/160467/. [Accessed 8th November 2023].</li>
														<li> Scwab, K. (2016) The Fourth Industrial Revolution: what it means, how to respond. Available from: https://www.weforum.org/agenda/2016/01/the-fourth-industrial-revolution-what-it-means-and-how-to-respond/. [Accessed 8th November 2023]</li>
														<li> Kostick-Quenet, K.M., Cohen, I.G., Gerke, S., Lo, B., Antaki, J., Movahedi, F., Njah, H., Schoen, L., Estep, J.E. & Blumenthal-Barby J.S. (2022) Mitigating Racial Bias in Machine Learning. Journal of Law, Medicine & Ethics. 50(1): 92-100.</li>
														<li>Gebru, T., Morgenstern, J., Vechhione, B., Vaughan, J.W., Wallach, H., Daume, H. & Crawford, K/ (2018) Datasheets for Datasets. CACM. DOI: https://doi.org/10.48550/arXiv.1803.09010</li>
														<li> The Guardian (2023) UK risks scandal over ‘bias’ in AI tools in use across public sector. Available from: https://www.theguardian.com/technology/2023/oct/23/uk-risks-scandal-over-bias-in-ai-tools-in-use-across-public-sector. [Accessed 01/01/2024]</li>
														<li> Business Reporter (2023) Reaching AI superpower status: the need to upskill the UK public sector. Available from: https://www.business-reporter.co.uk/technology/reaching-ai-superpower-status-the-need-to-upskill-the-uk-public-sector [Accessed 01/01/2024].</li>
														<li> Deloitte (2019) Five Challenges for government adoption of AI. Available from: https://www2.deloitte.com/ca/en/pages/deloitte-analytics/articles/government-adoption-of-ai.html [Accessed 01/01/2024]</li>
														<li>Department for Digital, Media, Culture and Sports (2021) Data foundations and AI adoption in the UK private and third sectors. Ernst and Young: London. </li>
														<li> Rao, D. (2023) The Urgent Need for Healthcare Workforce Upskilling and Ethical Considerations in the Era of AI – Assisted Medicine. Indian Journal of Otolaryngology and Head & Neck Surgery. 75(3). DOI: 10.1007/s12070-023-03755-9</li>
														<li> McAfee (2016) McAfee Labs Threats Report - Insight, Insight. Available at: https://www.insight.com/content/dam/insight-web/en_US/media/whitepaper/partner/McAfee%20Threats%20Report%20March%202016.pdf [Accessed: 10 November 2023].</li>
														<li> The Defence Science and Technology Laboratory (2023) Available from: https://www.gov.uk/government/publications/novel-disruptive-science-impacting-future-defence-and-security [Accessed 20 November 2023]</li>
														<li> Harboth, D., & Pape, S. (2021) Investigating privacy concerns related to mobile augmented reality Apps – A vignette-based online experiment. Computers in Human Behaviour. 122 DOI: https://doi.org/10.1016/j.chb.2021.106833</li>
														<li>Howard, A. & Borenstein, J (2018) The Ugly Truth About Ourselves and Our Robot Creations|: The Problem of Bias and Social Inequity. Science and Engineering Ethics, 24: 1521: 1536. DOI: https://doi.org/10.1007/s11948-017-9975-2. </li>
													</p>
                                    
								</div>
							</section>

					</div>

				<!-- Contact -->
					<section id="contact">
						<div class="inner">
							<section>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="6"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Clear" /></li>
									</ul>
								</form>
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">hamidabdul1996@gmail.com</a>
									</div>
								</section>
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-phone"></span>
										<h3>Phone</h3>
										<span></span>
									</div>
								</section>
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-home"></span>
										<h3>Address</h3>
										<span>1234 Somewhere Road #5432<br />
										Nashville, TN 00000<br />
										United States of America</span>
									</div>
								</section>
							</section>
						</div>
					</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
								<li><a href="https://github.com/HamidAbdul1996?tab=repositories?tab=repositories" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="https://www.linkedin.com/in/hamid-abdul-3ba206106/" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
© 2021 GitHub, Inc.
Terms
Privacy
Security
Status
Docs
Contact GitHub
Pricing
API
Training
Blog
About

