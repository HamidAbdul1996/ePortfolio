<!DOCTYPE HTML>
<!--
-->
<html>
	<head>
		<title>Generic - Forty by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo"><strong>hamidabdul</strong> <span></span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="landing.html">Landing</a></li>
							<li><a href="generic.html">Generic</a></li>
							<li><a href="elements.html">Elements</a></li>
						</ul>
						<ul class="actions stacked">
							<li><a href="#" class="button primary fit">Get Started</a></li>
							<li><a href="#" class="button fit">Log In</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main" class="alt">

						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h1>Introduction to Research Methods. The Scientific Investigation and Ethics in Computing.</h1>
									</header>
                                    <h4><u> Initial thoughts</u></h4>
                                    <p>
                                        I was particularly keen to start the research methods module as I want to be starting my dissertation as soon as possible. Having previously learned about research methods during my undergraduate studies, I felt equipped with a foundational understanding of the theory, even though it had been a few years since I last engaged with it. This initial unit served as a valuable refresher, solidifying my grasp of the distinction between deductive and inductive reasoning. It also highlighted the diverse motivations behind conducting research. Recognising whether one's research approach is primarily deductive or inductive is crucial, as it significantly influences research design, data collection methods, and subsequent analysis (Woiceshyn & Daellenbach, 2018).
                                    </p>
                                    <p>
                                        During this unit, I also selected my literature review topic: investigating the application of machine learning in detecting misinformation. This is a subject that deeply resonates with me, and I'm eager to start exploring the existing literature in this field. I may even do something related in my capstone project. I'm confident that the knowledge and skills I acquire in this module will be instrumental in my capstone project and I am excited to see how my understanding of research methods evolves throughout the program.
                                    </p>  
                                    
                                    <h4><u> Reflective Activity 1- Ethics in Computing in the Age of Generative AI</u></h4>
                                    <p>
                                        The article by Correa et al (2023) analyses 200 AI ethics guidelines from various countries and organisations, identifying 17 core principles that resonate globally. The most prevalent principles include transparency, accountability, fairness, privacy, and safety. These principles could offer a potential foundation for international AI regulation. However, it is important to note that the dataset used is skewed towards Western perspectives and lacks representation from Africa and South America. Additionally, the guidelines tend to focus on short-term AI risks rather than potential long-term issues like AI misalignment and existential threats. Furthermore, despite numerous proposed guidelines, few provide concrete implementation strategies. This suggests a need for greater inclusivity to incorporate diverse viewpoints, a shift from theoretical principles to actionable measures, and a focus on long-term risks alongside immediate AI safety concerns.
                                    </p>
                                    <p>
                                        In my opinion, generative AI holds the potential to transform our world, ushering in an era of unparalleled creativity and productivity. Like the printing press or the internet, this technology could reshape industries and change the way we work.  A report by the Oliver Wyman Forum (2024) estimates that generative AI could add $20 trillion to global GDP by 2030 and save 300 billion work hours annually. By automating repetitive tasks, it frees human workers to focus on higher-order thinking and innovation. In healthcare, for instance, generative AI could save doctors up to three hours a day, empowering them to serve an additional 500 million patients per year. Its potential to accelerate scientific breakthroughs is evident in DeepMind's protein-folding AI, which outperformed human experts (Lupas et al, 2021). However, we must acknowledge the profound challenges posed by generative AI. Job displacement, particularly in entry-level roles, is a major concern, with the World Economic Forum (2023) predicting the loss of 85 million positions by 2025. Additionally, generative AI carries the risk of perpetuating biases and facilitating the spread of misinformation. The surge in AI-generated fake news – with websites hosting such content increasing by over 1000% since May according to Newsguard (2024) – is alarming. Deepfakes used for political manipulation, as seen in Slovakia where videos of a politician whose voice had been cloned saying controversial things days before the election(Washington Post, 2023), highlight the urgent need to address these ethical dilemmas.
                                    </p>

                                    
                                    <p>
                                        In terms of guidelines, the rapid evolution of generative AI, with new models and updates emerging almost weekly, underscores the urgent need for cross-national regulatory agreements. Without clear, internationally binding guidelines, countries might disregard ethical considerations in the pursuit of short-term competitive advantages. This is particularly crucial with the recent surge of progress in AI. In 2014 Ray Kurzweil, the head of Google Engineering stated AI will have human-level intelligence by 2029 and could achieve singularity by 2045, the point when “we will multiply our effective intelligence a billion-fold by merging with the intelligence we have created” (Guardian, 2014). With the current pace of progress, this could happen much sooner than expected. This breakneck pace of AI development poses a challenge for traditional risk assessment. By the time regulations are drafted, the technology may have already advanced significantly. To address this, I think establishing an independent regulatory body with diverse representation – including government, industry, and social stakeholders from all countries is vital. This body should work with strict timelines and deadlines to outline clear AI development and deployment guidelines. While AI holds the potential for unprecedented productivity gains, it's equally important to acknowledge the existential risks, as highlighted by the statement on AI released by the Centre for AI Safety (2023). 
                                    </p>
                                    <p><i>
                                        “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.”
                                    </i></p>
                                    <p>
                                        The rapid proliferation of generative AI necessitates a comprehensive revision of existing legal frameworks.  Crucial areas include copyright, privacy, and liability.  With generative AI's ability to produce outputs closely resembling existing works, clear laws are required to determine ownership rights and address potential infringement. Should a human user of AI be considered the primary creator, or does the AI system itself hold some claim? Similarly, privacy concerns demand new laws and regulations to protect personal data.  These must outline responsible data collection practices, minimise unnecessary data usage, and ensure individuals maintain robust control over their information. Furthermore, the issue of liability requires urgent attention. In cases of harm caused by AI-generated content (such as the spread of misinformation), it's vital to establish clear legal responsibility.  Strict liability laws could incentivise meticulous oversight of AI outputs and deter negligent use.  Such measures would foster public trust, which is increasingly undermined by the abundance of dubious online content. From a professional standpoint, organisations deploying generative AI will likely require in-house expertise on AI ethics. Data scientists, lawyers, or other professionals with a deep understanding of AI's intricacies are essential for responsible development and usage. This could also lead to an entirely new insurance sector specialising in mitigating AI-related risks.
                                    </p>
                                    <p>
                                        To conclude the rise of generative AI demands a comprehensive global response.  While Correa et al. offer a valuable starting point by identifying core AI ethics principles, their work underscores the need for greater inclusivity and a proactive stance on both near and long-term risks.  To address copyright, privacy, and liability concerns, nations must urgently collaborate to establish clear legal frameworks. Cross-national agreements are paramount to prevent ethical compromises in the pursuit of short-term advantage. An independent regulatory body comprised of diverse stakeholders must work swiftly to develop actionable AI guidelines and address the potential existential risks it poses. This collaborative, proactive approach is crucial for ensuring that generative AI serves as a force for progress,  rather than a tool for disruption and harm.
                                    </p>

                                    <h4><u> Reflection </u></h4>
                                    <p>
                                        Reflecting on the piece around generative AI, I've gained a deeper understanding of its transformative potential and the ethical complexities it presents. The  scale of its projected impact on the global economy and workforce is enormous. Yet, the potential for job displacement and the proliferation of misinformation are serious concerns that cannot be ignored.
                                        One of my key takeaways is around moving beyond theoretical principles to concrete action. The abundance of AI ethics guidelines, while valuable, often lacks actionable strategies. In my future work, I will strive to bridge this gap by focusing on practical implementation. 
                                        Finally, the existential risks associated with AI, while seemingly distant, cannot be dismissed. As I continue my work in this field, I will remain mindful of these long-term concerns and actively participate in discussions about responsible AI development. This could involve contributing to research on AI safety or engaging in public discourse to raise awareness about the potential risks and benefits of this transformative technology.

                                    </p>

                                    <h4><u> Reference List</u></h4>	
                                    <p>
                                        <li>Correa, N.K., Galvao, C., Santos, J.W., Del Pino, C., Pinto, E.P., Barbosa, C., Massmann, D., Mabrini, R., Galvao, L., Terem, E. & de Oliveria, N. (2023) Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance. Patterns. 4(10). DOI: https://doi.org/10.1016/j.patter.2023.100857</li>
                                        <li>Centre for AI safety (2023) Statement on AI risk. Available from: https://www.safe.ai/work/statement-on-ai-risk#open-letter [Accessed 16/03/2024]</li>
                                        <li> The Guardian (2014) 2029: the year when robots will have the power to outsmart their makers. Available from: https://www.theguardian.com/technology/2014/feb/22/computers-cleverer-than-humans-15-years [Accessed 16/03/2024]</li>
                                        <li> Lupas, A.N., Pereira, J., Alva, V., Merino, F., Coles & Hartman, M.D. (2021) The breakthrough in protein structure prediction. Biochemistry Journal. 478(10): 1885-1890</li>
                                        <li> Newsguard (2024) Tracking AI-enabled Misinformation. Available from  https://www.newsguardtech.com/special-reports/ai-tracking-center/. [Accessed 14/03/2024].</li>
                                        <li> Oliver Wyman Forum (2024) How Generative AI Is Transforming Business and Society. Available from: https://www.oliverwymanforum.com/global-consumer-sentiment/how-will-ai-affect-global-economics.html. [Accessed 14/03/2024].</li>
                                        <li> Washington Post (2023) AI voice clones mimic politicians and celebrities, reshaping reality. Available from: https://www.washingtonpost.com/technology/2023/10/13/ai-voice-cloning-deepfakes/. [Accessed 14/03/2024].</li>
                                        <li> Woiceshyn, J., & Daellenbach, U. (2018). Evaluating inductive vs deductive research in management studies: Implications for authors, editors, and reviewers. Qualitative Research in Organizations and Management: An International Journal, 13(2), 183–195.</li>
                                        <li> World Economic Forum (2023) Future of Jobs Report 2023 Insight Report May 2023. Available from: https://www3.weforum.org/docs/WEF_Future_of_Jobs_2023.pdf. [Accessed 14/03/2024].</li>
                                    </p>
									<span class="image main"><img src="images/pic11.jp" alt="" /></span>
									
			
                                    
								</div>
							</section>

					</div>

				<!-- Contact -->
					<section id="contact">
						<div class="inner">
							<section>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="6"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Clear" /></li>
									</ul>
								</form>
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">hamidabdul1996@gmail.com</a>
									</div>
								</section>
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-phone"></span>
										<h3>Phone</h3>
										<span></span>
									</div>
								</section>
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-home"></span>
										<h3>Address</h3>
										<span><br />
										<br />
										</span>
									</div>
								</section>
							</section>
						</div>
					</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
								<li><a href="https://github.com/HamidAbdul1996?tab=repositories?tab=repositories" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="https://www.linkedin.com/in/hamid-abdul-3ba206106/" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
© 2021 GitHub, Inc.
Terms
Privacy
Security
Status
Docs
Contact GitHub
Pricing
API
Training
Blog
About
